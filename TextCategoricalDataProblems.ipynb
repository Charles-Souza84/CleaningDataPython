{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorias inconsistentes\n",
    "\n",
    "Será feita uma análise dos dados contigos no dataframe airlines, mais especificamente nas colunas dest_region e dest_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asia' 'Canada/Mexico' 'West US' 'East US' 'Midwest US' 'EAST US'\n",
      " 'Middle East' 'Europe' 'eur' 'Central/South America'\n",
      " 'Australia/New Zealand' 'middle east']\n",
      "['Hub' 'Small' '    Hub' 'Medium' 'Large' 'Hub     ' '    Small'\n",
      " 'Medium     ' '    Medium' 'Small     ' '    Large' 'Large     ']\n",
      "['asia' 'canada/mexico' 'west us' 'east us' 'midwest us' 'middle east'\n",
      " 'europe' 'central/south america' 'australia/new zealand']\n",
      "['Hub' 'Small' 'Medium' 'Large']\n"
     ]
    }
   ],
   "source": [
    "# importando Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# carregando o arquivo 'airlines_final.csv\n",
    "filename = 'airlines_final.csv'\n",
    "airlines = pd.read_csv(filename)\n",
    "\n",
    "# imprimindo valores únicos de ambas colunas\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n",
    "\n",
    "# convertendo para caixa baixa a coluna dest_region e substituindo \"eur\" por \"europe\"\n",
    "airlines['dest_region'] = airlines['dest_region'].str.lower()\n",
    "airlines['dest_region'] = airlines['dest_region'].replace({'eur':'europe'})\n",
    "\n",
    "# removendo espaços em branco de `dest_size`\n",
    "airlines['dest_size'] = airlines['dest_size'].str.strip()\n",
    "\n",
    "# conferindo se as mudanças foram feitas corretamente\n",
    "print(airlines['dest_region'].unique())\n",
    "print(airlines['dest_size'].unique())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remapeando categorias\n",
    "\n",
    "O dataframe airlines contem as colunas <code>day</code> e <code>wait_min</code> que são categórica e numérica,respectivamente. \n",
    "\n",
    "* day - armazena o dia em que o voo ocorreu\n",
    "* wait_min - armazena o tempo em minutos que os passageiros aguardaram no portão de embarque\n",
    "\n",
    "Nesta etapa serão criadas novas categorias :\n",
    "\n",
    "* wait_type\n",
    "    * short - 0-60 min\n",
    "    * medium - 60-180 min\n",
    "    * long - 180+ \n",
    "\n",
    "* day_week \n",
    "    * weekday - se o dia for durante a semana\n",
    "    * weekend - se o dia for final de semana\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a biblioteca Numpy\n",
    "import numpy as np\n",
    "\n",
    "# criando intervalos para as categorias\n",
    "# np.inf representa infinito, tão grande quanto se queira\n",
    "label_ranges = [0, 60, 180, np.inf]\n",
    "label_names = ['short', 'medium', 'long']\n",
    "\n",
    "# criando a coluna wait_type\n",
    "airlines['wait_type'] = pd.cut(airlines['wait_min'], bins = label_ranges, labels = label_names)\n",
    "\n",
    "# criando mappings e substituindo\n",
    "mappings = {'Monday':'weekday', 'Tuesday':'weekday', 'Wednesday': 'weekday', \n",
    "            'Thursday': 'weekday', 'Friday': 'weekday', \n",
    "            'Saturday': 'weekend', 'Sunday': 'weekend'}\n",
    "\n",
    "airlines['day_week'] = airlines['day'].replace(mappings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a42ccb73e7d9bfdf27e036f1d2b8b681e55fc0743cc5586bc2474d4a60f4b886"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
